{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "from google.colab import drive\n",
        "import os\n",
        "import torch"
      ],
      "metadata": {
        "id": "vRsGs7vPFuaE"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "if not os.path.exists('/content/drive'):\n",
        "    drive.mount('/content/drive')\n",
        "else:\n",
        "    print(\"Drive ya está montado\")\n",
        "\n",
        "# Ruta base en Google Drive donde se guarda el modelo\n",
        "BASE_PATH = \"/content/drive/MyDrive/ProyectoFinal\"\n",
        "MODEL_PATH = f\"{BASE_PATH}/FineTuning/DeepESP_gpt2-spanish/full_fine_tuning_v4\"\n",
        "DATA_FOLDER = f\"{MODEL_PATH}/Data\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ohon4yWGkiE",
        "outputId": "f2bfca94-68ab-4cd8-8a86-06e009afea00"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download(\"stopwords\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flplv2xSUjYm",
        "outputId": "07fbe215-20a8-4713-9e56-2aabb4c0ac7f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import gradio as gr\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "import io\n",
        "from PIL import Image\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "artist_data_dict = {}\n",
        "\n",
        "for filename in os.listdir(DATA_FOLDER):\n",
        "    if filename.endswith(\".json\"):\n",
        "        filepath = os.path.join(DATA_FOLDER, filename)\n",
        "        with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
        "            artist_json = json.load(f)\n",
        "            artist_name = artist_json.get(\"name\", \"Unknown\")\n",
        "            songs = artist_json.get(\"songs\", [])\n",
        "            lyrics = [song.get(\"lyric\", \"\") for song in songs if song.get(\"lyric\")]\n",
        "            if artist_name in artist_data_dict:\n",
        "                artist_data_dict[artist_name][\"lyrics\"].extend(lyrics)\n",
        "            else:\n",
        "                artist_data_dict[artist_name] = {\n",
        "                    \"filename\": filename,\n",
        "                    \"lyrics\": lyrics\n",
        "                }\n",
        "\n",
        "artist_names = sorted(artist_data_dict.keys())\n",
        "\n",
        "# --- FUNCIONES DE VISUALIZACIÓN ---\n",
        "# desestimar las palabras más comunes (\"el\", \"la\", \"de\", \"y\", \"que\", etc.):\n",
        "spanish_stopwords = set(stopwords.words(\"spanish\"))\n",
        "\n",
        "def generar_visualizaciones(artist_name, top_n=30):\n",
        "    lyrics = \" \".join(artist_data_dict[artist_name][\"lyrics\"]).lower()\n",
        "\n",
        "    # Tokenización simple\n",
        "    words = lyrics.split()\n",
        "\n",
        "    # Filtro: eliminar palabras cortas y stopwords\n",
        "    filtered_words = [w for w in words if len(w) > 3 and w not in spanish_stopwords]\n",
        "\n",
        "    word_counts = Counter(filtered_words)\n",
        "    most_common = word_counts.most_common(top_n)\n",
        "\n",
        "    if most_common:\n",
        "        palabras, frecuencias = zip(*most_common)\n",
        "    else:\n",
        "        palabras, frecuencias = [], []\n",
        "\n",
        "    # --- Histograma ---\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.bar(palabras, frecuencias, color=\"skyblue\")\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.title(f\"Top {top_n} palabras más frecuentes de {artist_name}\")\n",
        "    plt.tight_layout()\n",
        "\n",
        "    hist_buf = io.BytesIO()\n",
        "    plt.savefig(hist_buf, format='png')\n",
        "    plt.close()\n",
        "    hist_buf.seek(0)\n",
        "\n",
        "    # --- Nube de palabras ---\n",
        "    wordcloud = WordCloud(\n",
        "        width=600, height=400,\n",
        "        background_color='white',\n",
        "        stopwords=spanish_stopwords\n",
        "    ).generate(\" \".join(filtered_words))\n",
        "\n",
        "    cloud_buf = io.BytesIO()\n",
        "    wordcloud.to_image().save(cloud_buf, format='PNG')\n",
        "    cloud_buf.seek(0)\n",
        "\n",
        "    return Image.open(hist_buf), Image.open(cloud_buf)\n",
        "\n",
        "interface = gr.Interface(\n",
        "    fn=generar_visualizaciones,\n",
        "    inputs=[\n",
        "        gr.Dropdown(choices=artist_names, label=\"Seleccionar artista\"),\n",
        "        gr.Slider(minimum=10, maximum=100, step=5, value=30, label=\"Cantidad de palabras en el histograma\")\n",
        "    ],\n",
        "    outputs=[\n",
        "        gr.Image(type=\"pil\", label=\"Histograma de palabras\"),\n",
        "        gr.Image(type=\"pil\", label=\"Nube de palabras\")\n",
        "    ],\n",
        "    title=\"Análisis de letras por artista\",\n",
        "    description=\"Visualiza las palabras más frecuentes de las letras en el dataset por artista (histograma y nube de palabras).\"\n",
        ")\n",
        "\n",
        "interface.launch(share=True)"
      ],
      "metadata": {
        "id": "tTRjKfRTVDlV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}