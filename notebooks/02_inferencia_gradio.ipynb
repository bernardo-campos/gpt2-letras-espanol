{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "En este notebook se carga el modelo desde Google Drive y se ejecuta la interfaz para realizar las inferencias"
      ],
      "metadata": {
        "id": "Dl_qbFBjM4CN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "游댳 Listado de artistas obtenidos del dataset de entrenamiento"
      ],
      "metadata": {
        "id": "Jd6lc2hwF7c4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WkPi3XWbGLQE"
      },
      "outputs": [],
      "source": [
        "artist_names = [\n",
        "    'Andr칠s Calamaro',\n",
        "    'Chaque침o Palavecino',\n",
        "    'Fito P치ez',\n",
        "    'Horacio Guarany',\n",
        "    'Jairo',\n",
        "    'Juan Gabriel',\n",
        "    'La Barra',\n",
        "    'Leo Dan',\n",
        "    'Litto Nebbia',\n",
        "    'Los Chalchaleros',\n",
        "    'Los Palmeras',\n",
        "    'Mercedes Sosa',\n",
        "    'Pablo Milan칠s',\n",
        "    'Palito Ortega',\n",
        "    'Raphael',\n",
        "    'Roc칤o D칰rcal',\n",
        "    'Sabroso',\n",
        "    'Sandro',\n",
        "    'Ulises Bueno',\n",
        "    'V칤ctor Heredia'\n",
        "]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "游댳 Carga del modelo desde Google Drive"
      ],
      "metadata": {
        "id": "HdwojgeAGHae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "from google.colab import drive\n",
        "import os\n",
        "import torch"
      ],
      "metadata": {
        "id": "vRsGs7vPFuaE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "if not os.path.exists('/content/drive'):\n",
        "    drive.mount('/content/drive')\n",
        "else:\n",
        "    print(\"Drive ya est치 montado\")\n",
        "\n",
        "# Ruta base en Google Drive donde se guarda el modelo\n",
        "BASE_PATH = \"/content/drive/MyDrive/ProyectoFinal\"\n",
        "MODEL_PATH = f\"{BASE_PATH}/FineTuning/DeepESP_gpt2-spanish/full_fine_tuning_v4\"\n",
        "\n",
        "print(\"Cargando modelo reentrenado desde Google Drive...\")\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(MODEL_PATH)\n",
        "tokenizer.pad_token = \"<pad>\"\n",
        "tokenizer.bos_token = \"<bos>\"\n",
        "tokenizer.eos_token = \"<eos>\"\n",
        "model = GPT2LMHeadModel.from_pretrained(MODEL_PATH)\n",
        "\n",
        "# Mover el modelo al dispositivo\n",
        "model = model.to(device)\n",
        "print(f\"Modelo en: {next(model.parameters()).device}\")\n",
        "\n",
        "# Verificar que los tokens especiales est칠n correctamente configurados:\n",
        "print(f\"Tokens especiales: {tokenizer.special_tokens_map}\")\n",
        "print(f\"ID de <lyr>: {tokenizer.encode('<lyr>')}\")\n",
        "print(f\"ID de <art>: {tokenizer.encode('<art>')}\")\n",
        "print(f\"ID de <eos>: {tokenizer.encode('<eos>')}\")\n",
        "\n",
        "print(f\"Tama침o vocabulario tokenizer: {len(tokenizer)}\")\n",
        "print(f\"Tama침o embeddings modelo: {model.get_input_embeddings().weight.shape[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ohon4yWGkiE",
        "outputId": "1c326598-c68b-4f59-d300-d1b1c90ed0bc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive ya est치 montado\n",
            "Cargando modelo reentrenado desde Google Drive...\n",
            "Modelo en: cuda:0\n",
            "Tokens especiales: {'bos_token': '<bos>', 'eos_token': '<eos>', 'unk_token': '<|endoftext|>', 'pad_token': '<pad>', 'additional_special_tokens': ['<|talk|>', '<|ax1|>', '<|ax2|>', '<|ax3|>', '<|ax4|>', '<|ax5|>', '<|ax6|>', '<|ax7|>', '<|ax8|>', '<|ax9|>']}\n",
            "ID de <lyr>: [50261]\n",
            "ID de <art>: [50260]\n",
            "ID de <eos>: [50259]\n",
            "Tama침o vocabulario tokenizer: 50262\n",
            "Tama침o embeddings modelo: 50262\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "游댳 Interfaz Gradio para realizar las inferencias"
      ],
      "metadata": {
        "id": "gLpXwHd9NMEw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import tempfile\n",
        "\n",
        "# Funci칩n para generar texto con par치metros personalizables\n",
        "def generate_text(artist, max_new_tokens, temperature, top_k, top_p, repetition_penalty, no_repeat_ngram_size):\n",
        "    model.eval()\n",
        "    inputs = tokenizer(f\"<bos><art>{artist}<lyr>\", return_tensors=\"pt\")\n",
        "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=int(max_new_tokens),  # Controla la cantidad de nuevos tokens generados\n",
        "        temperature=float(temperature),      # Controla la aleatoriedad (solo si do_sample=True)\n",
        "        top_k=int(top_k),                    # Top-k sampling\n",
        "        top_p=float(top_p),                  # Top-p (nucleus) sampling\n",
        "        do_sample=True,                      # Habilita muestreo (permite aleatoriedad - no determinismo)\n",
        "        pad_token_id=tokenizer.pad_token_id, # Evita advertencias\n",
        "        eos_token_id=tokenizer.eos_token_id, # Evita advertencias\n",
        "        repetition_penalty=float(repetition_penalty),\n",
        "        no_repeat_ngram_size=int(no_repeat_ngram_size),\n",
        "    )\n",
        "\n",
        "    text = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
        "\n",
        "    # Guardar en archivo temporal para descarga\n",
        "    with tempfile.NamedTemporaryFile(delete=False, mode='w', suffix='.txt') as f:\n",
        "        f.write(text)\n",
        "        file_path = f.name\n",
        "\n",
        "    return text, file_path\n",
        "\n",
        "# Crear la interfaz de Gradio\n",
        "interface = gr.Interface(\n",
        "    fn=generate_text,\n",
        "    inputs=[\n",
        "        gr.Dropdown(choices=artist_names, label=\"Artista\"),\n",
        "        gr.Slider(minimum=50, maximum=768, value=512, step=1, label=\"M치ximo de nuevos tokens\"),\n",
        "        gr.Slider(minimum=0.1, maximum=2.0, value=.8, step=0.1, label=\"Temperature\"),\n",
        "        gr.Slider(minimum=1, maximum=100, value=25, step=1, label=\"Top K\"),\n",
        "        gr.Slider(minimum=0.1, maximum=1.0, value=0.75, step=0.05, label=\"Top P\"),\n",
        "        gr.Slider(1.0, 2.0, value=1.4, step=0.1, label=\"Repetition Penalty\"),\n",
        "        gr.Slider(0, 10, value=4, step=1, label=\"No Repeat N-Gram Size\"),\n",
        "    ],\n",
        "    theme=\"default\",\n",
        "    outputs=[\n",
        "        gr.Textbox(label=\"Texto generado\"),\n",
        "        gr.File(label=\"Descargar texto\")\n",
        "    ],\n",
        "    title=f\"Generar una letra de canci칩n (usando el modelo DeepESP/gpt2-spanish)\",\n",
        "    description=f\"Elegir un artista y ajusta los par치metros para generar texto con modelo GPT-2 fine-tuneado. Usando {device.upper()}.\"\n",
        ")\n",
        "\n",
        "# Lanzar la interfaz\n",
        "interface.launch(share=True)"
      ],
      "metadata": {
        "id": "enUEigcBG13h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}